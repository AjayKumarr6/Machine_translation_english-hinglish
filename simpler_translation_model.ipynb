{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "IH7P8WOkq2fR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DhKFKGgcpuLG"
      },
      "outputs": [],
      "source": [
        "# Define a function to keep certain words in English\n",
        "def keep_english_words(translation):\n",
        "    english_words = ['demo', 'headset', 'feedback', 'comment', 'section',\n",
        "                     'video', 'products', 'bag']\n",
        "    for word in english_words:\n",
        "        translation = translation.replace(word, f'[{word}]')\n",
        "    return translation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to translate English to Hinglish\n",
        "def translate_to_hinglish(input_text):\n",
        "    try:\n",
        "        input_tokens = input_text.split()\n",
        "        output_tokens = []\n",
        "\n",
        "        for token in input_tokens:\n",
        "            if token.lower() in english_words:\n",
        "                output_tokens.append(f\"[{token}]\")\n",
        "            else:\n",
        "                output_tokens.append(translation_mapping.get(token.lower(), token))\n",
        "\n",
        "        hinglish_translation = ' '.join(output_tokens)\n",
        "        return hinglish_translation\n",
        "    except Exception as e:\n",
        "        return str(e)"
      ],
      "metadata": {
        "id": "zzE4QmCup0rZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample English sentences\n",
        "english_sentences = [\n",
        "    \"Definitely share your feedback in the comment section.\",\n",
        "    \"So even if it's a big video, I will clearly mention all the products.\",\n",
        "    \"I was waiting for my bag.\"\n",
        "]\n",
        "\n",
        "# Create a set of English words to keep\n",
        "english_words = {'demo', 'headset', 'feedback', 'comment', 'section',\n",
        "                 'video', 'products', 'bag'}\n",
        "\n",
        "# Mapping of English to Hinglish for non-English words\n",
        "translation_mapping = {\n",
        "    \"definitely\": \"ज़रूर\",\n",
        "    \"share\": \"साझा\",\n",
        "    \"your\": \"तुम्हारी\",\n",
        "    \"in\": \"में\",\n",
        "    \"the\": \"यह\",\n",
        "    \"so\": \"तो\",\n",
        "    \"even\": \"यहाँ तक कि\",\n",
        "    \"it's\": \"यह है\",\n",
        "    \"a\": \"एक\",\n",
        "    \"big\": \"बड़ा\",\n",
        "    \"I\": \"मैं\",\n",
        "    \"will\": \"मैं\",\n",
        "    \"clearly\": \"स्पष्ट रूप से\",\n",
        "    \"mention\": \"उल्लेख\",\n",
        "    \"all\": \"सभी\",\n",
        "    \"the\": \"यह\",\n",
        "    \"I\": \"मैं\",\n",
        "    \"was\": \"था\",\n",
        "    \"waiting\": \"इंतजार\",\n",
        "    \"for\": \"के लिए\",\n",
        "    \"my\": \"मेरी\",\n",
        "    \"bag\": \"बैग\"\n",
        "}\n",
        "\n",
        "# Define the inverse translation mapping\n",
        "translation_mapping_inv = {v: k for k, v in translation_mapping.items()}"
      ],
      "metadata": {
        "id": "3DppjxDOqDM_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the inverse translation mapping\n",
        "translation_mapping_inv = {v: k for k, v in translation_mapping.items()}\n",
        "\n",
        "# Combine translation and Seq2Seq model\n",
        "\n",
        "# Define a simple sequence-to-sequence model\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        embedded = self.encoder(input_seq)\n",
        "        output_seq = self.decoder(embedded)\n",
        "        return output_seq\n",
        "\n",
        "# Dummy data for training\n",
        "input_size = 50  # Vocabulary size for English\n",
        "hidden_size = 128\n",
        "output_size = 50  # Vocabulary size for Hinglish"
      ],
      "metadata": {
        "id": "wy2QSqHBqOsL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "model = Seq2Seq(input_size, hidden_size, output_size)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Dummy input sequence\n",
        "input_seq = torch.tensor([1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "id": "u8bwrC0Qq3zG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    output_seq = model(input_seq)\n",
        "\n",
        "    # Dummy target sequence\n",
        "    target_seq = torch.tensor([6, 7, 8, 9, 10])\n",
        "\n",
        "    loss = criterion(output_seq, target_seq)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Inference (translating English to Hinglish)\n",
        "input_seq = torch.tensor([1,2,3,4,5])\n",
        "output_seq = model(input_seq)\n",
        "output_indices = torch.argmax(output_seq, dim=1)\n",
        "predicted_hinglish_sentence = ' '.join([translation_mapping_inv.get(idx.item(), str(idx.item())) for idx in output_indices])\n",
        "\n",
        "# Print results\n",
        "print(\"English Sentence:\")\n",
        "print(english_sentences)  # Print the first English sentence\n",
        "print(predicted_hinglish_sentence)  # Print the predicted Hinglish sentence\n",
        "\n",
        "# Translate and print Hinglish sentences for the rest of the English sentences\n",
        "for i in range(1, len(english_sentences)):\n",
        "    hinglish_translation = translate_to_hinglish(english_sentences[i])\n",
        "    hinglish_translation = keep_english_words(hinglish_translation)\n",
        "    print(f\"\\nEnglish: {english_sentences[i]}\")\n",
        "    print(f\"Hinglish: {hinglish_translation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikdrL4aSqkQf",
        "outputId": "995ff6cd-298b-43f5-ad6a-be338d88bd09"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/100], Loss: 0.0398\n",
            "English Sentence:\n",
            "['Definitely share your feedback in the comment section.', \"So even if it's a big video, I will clearly mention all the products.\", 'I was waiting for my bag.']\n",
            "6 7 8 9 10\n",
            "\n",
            "English: So even if it's a big video, I will clearly mention all the products.\n",
            "Hinglish: तो यहाँ तक कि if यह है एक बड़ा [video], I मैं स्पष्ट रूप से उल्लेख सभी यह [products].\n",
            "\n",
            "English: I was waiting for my bag.\n",
            "Hinglish: I था इंतजार के लिए मेरी [bag].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1I8b_ZEQtM5g"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}